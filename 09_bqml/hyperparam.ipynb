{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter tuning of BigQuery ML models\n",
    "\n",
    "This notebook shows you a couple of ways to do hyperparameter tuning of BigQuery ML models\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1a. Grid Search from Python\n",
    "\n",
    "Let's try to find the optimal K for a k-means clustering model by trying out all possible values of K within a specified range."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On Notebook instances in Google Cloud, these are already installed\n",
    "#!python -m pip install google-cloud-bigquery\n",
    "#%load_ext google.cloud.bigquery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from multiprocessing.dummy import Pool as ThreadPool\n",
    "from google.cloud import bigquery\n",
    "import numpy as np\n",
    "PROJECT='cloud-training-demos'  # CHANGE THIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grid search of 17 possible parameters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/google/auth/_default.py:66: UserWarning: Your application has authenticated using end user credentials from Google Cloud SDK. We recommend that most server applications use service accounts instead. If your application continues to use end user credentials from Cloud SDK, you might receive a \"quota exceeded\" or \"API not enabled\" error. For more information about service accounts, see https://cloud.google.com/docs/authentication/\n",
      "  warnings.warn(_CLOUD_SDK_CREDENTIALS_WARNING)\n",
      "/usr/local/lib/python3.5/dist-packages/google/auth/_default.py:66: UserWarning: Your application has authenticated using end user credentials from Google Cloud SDK. We recommend that most server applications use service accounts instead. If your application continues to use end user credentials from Cloud SDK, you might receive a \"quota exceeded\" or \"API not enabled\" error. For more information about service accounts, see https://cloud.google.com/docs/authentication/\n",
      "  warnings.warn(_CLOUD_SDK_CREDENTIALS_WARNING)\n",
      "/usr/local/lib/python3.5/dist-packages/google/auth/_default.py:66: UserWarning: Your application has authenticated using end user credentials from Google Cloud SDK. We recommend that most server applications use service accounts instead. If your application continues to use end user credentials from Cloud SDK, you might receive a \"quota exceeded\" or \"API not enabled\" error. For more information about service accounts, see https://cloud.google.com/docs/authentication/\n",
      "  warnings.warn(_CLOUD_SDK_CREDENTIALS_WARNING)\n",
      "/usr/local/lib/python3.5/dist-packages/google/auth/_default.py:66: UserWarning: Your application has authenticated using end user credentials from Google Cloud SDK. We recommend that most server applications use service accounts instead. If your application continues to use end user credentials from Cloud SDK, you might receive a \"quota exceeded\" or \"API not enabled\" error. For more information about service accounts, see https://cloud.google.com/docs/authentication/\n",
      "  warnings.warn(_CLOUD_SDK_CREDENTIALS_WARNING)\n",
      "/usr/local/lib/python3.5/dist-packages/google/auth/_default.py:66: UserWarning: Your application has authenticated using end user credentials from Google Cloud SDK. We recommend that most server applications use service accounts instead. If your application continues to use end user credentials from Cloud SDK, you might receive a \"quota exceeded\" or \"API not enabled\" error. For more information about service accounts, see https://cloud.google.com/docs/authentication/\n",
      "  warnings.warn(_CLOUD_SDK_CREDENTIALS_WARNING)\n",
      "/usr/local/lib/python3.5/dist-packages/google/auth/_default.py:66: UserWarning: Your application has authenticated using end user credentials from Google Cloud SDK. We recommend that most server applications use service accounts instead. If your application continues to use end user credentials from Cloud SDK, you might receive a \"quota exceeded\" or \"API not enabled\" error. For more information about service accounts, see https://cloud.google.com/docs/authentication/\n",
      "  warnings.warn(_CLOUD_SDK_CREDENTIALS_WARNING)\n",
      "/usr/local/lib/python3.5/dist-packages/google/auth/_default.py:66: UserWarning: Your application has authenticated using end user credentials from Google Cloud SDK. We recommend that most server applications use service accounts instead. If your application continues to use end user credentials from Cloud SDK, you might receive a \"quota exceeded\" or \"API not enabled\" error. For more information about service accounts, see https://cloud.google.com/docs/authentication/\n",
      "  warnings.warn(_CLOUD_SDK_CREDENTIALS_WARNING)\n",
      "/usr/local/lib/python3.5/dist-packages/google/auth/_default.py:66: UserWarning: Your application has authenticated using end user credentials from Google Cloud SDK. We recommend that most server applications use service accounts instead. If your application continues to use end user credentials from Cloud SDK, you might receive a \"quota exceeded\" or \"API not enabled\" error. For more information about service accounts, see https://cloud.google.com/docs/authentication/\n",
      "  warnings.warn(_CLOUD_SDK_CREDENTIALS_WARNING)\n",
      "/usr/local/lib/python3.5/dist-packages/google/auth/_default.py:66: UserWarning: Your application has authenticated using end user credentials from Google Cloud SDK. We recommend that most server applications use service accounts instead. If your application continues to use end user credentials from Cloud SDK, you might receive a \"quota exceeded\" or \"API not enabled\" error. For more information about service accounts, see https://cloud.google.com/docs/authentication/\n",
      "  warnings.warn(_CLOUD_SDK_CREDENTIALS_WARNING)\n",
      "/usr/local/lib/python3.5/dist-packages/google/auth/_default.py:66: UserWarning: Your application has authenticated using end user credentials from Google Cloud SDK. We recommend that most server applications use service accounts instead. If your application continues to use end user credentials from Cloud SDK, you might receive a \"quota exceeded\" or \"API not enabled\" error. For more information about service accounts, see https://cloud.google.com/docs/authentication/\n",
      "  warnings.warn(_CLOUD_SDK_CREDENTIALS_WARNING)\n",
      "/usr/local/lib/python3.5/dist-packages/google/auth/_default.py:66: UserWarning: Your application has authenticated using end user credentials from Google Cloud SDK. We recommend that most server applications use service accounts instead. If your application continues to use end user credentials from Cloud SDK, you might receive a \"quota exceeded\" or \"API not enabled\" error. For more information about service accounts, see https://cloud.google.com/docs/authentication/\n",
      "  warnings.warn(_CLOUD_SDK_CREDENTIALS_WARNING)\n",
      "/usr/local/lib/python3.5/dist-packages/google/auth/_default.py:66: UserWarning: Your application has authenticated using end user credentials from Google Cloud SDK. We recommend that most server applications use service accounts instead. If your application continues to use end user credentials from Cloud SDK, you might receive a \"quota exceeded\" or \"API not enabled\" error. For more information about service accounts, see https://cloud.google.com/docs/authentication/\n",
      "  warnings.warn(_CLOUD_SDK_CREDENTIALS_WARNING)\n",
      "/usr/local/lib/python3.5/dist-packages/google/auth/_default.py:66: UserWarning: Your application has authenticated using end user credentials from Google Cloud SDK. We recommend that most server applications use service accounts instead. If your application continues to use end user credentials from Cloud SDK, you might receive a \"quota exceeded\" or \"API not enabled\" error. For more information about service accounts, see https://cloud.google.com/docs/authentication/\n",
      "  warnings.warn(_CLOUD_SDK_CREDENTIALS_WARNING)\n",
      "/usr/local/lib/python3.5/dist-packages/google/auth/_default.py:66: UserWarning: Your application has authenticated using end user credentials from Google Cloud SDK. We recommend that most server applications use service accounts instead. If your application continues to use end user credentials from Cloud SDK, you might receive a \"quota exceeded\" or \"API not enabled\" error. For more information about service accounts, see https://cloud.google.com/docs/authentication/\n",
      "  warnings.warn(_CLOUD_SDK_CREDENTIALS_WARNING)\n",
      "/usr/local/lib/python3.5/dist-packages/google/auth/_default.py:66: UserWarning: Your application has authenticated using end user credentials from Google Cloud SDK. We recommend that most server applications use service accounts instead. If your application continues to use end user credentials from Cloud SDK, you might receive a \"quota exceeded\" or \"API not enabled\" error. For more information about service accounts, see https://cloud.google.com/docs/authentication/\n",
      "  warnings.warn(_CLOUD_SDK_CREDENTIALS_WARNING)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ch09eu.london_station_clusters_19          1.400756    19\n",
      "ch09eu.london_station_clusters_15          1.415517    15\n",
      "ch09eu.london_station_clusters_18          1.429912    18\n",
      "ch09eu.london_station_clusters_14          1.438088    14\n",
      "ch09eu.london_station_clusters_13          1.438440    13\n",
      "ch09eu.london_station_clusters_17          1.454715    17\n",
      "ch09eu.london_station_clusters_16          1.456185    16\n",
      "ch09eu.london_station_clusters_11          1.502263    11\n",
      "ch09eu.london_station_clusters_12          1.511940    12\n",
      "ch09eu.london_station_clusters_10          1.529150    10\n",
      "ch09eu.london_station_clusters_7           1.551265     7\n",
      "ch09eu.london_station_clusters_9           1.571020     9\n",
      "ch09eu.london_station_clusters_6           1.571398     6\n",
      "ch09eu.london_station_clusters_4           1.596398     4\n",
      "ch09eu.london_station_clusters_8           1.621974     8\n",
      "ch09eu.london_station_clusters_5           1.660766     5\n",
      "ch09eu.london_station_clusters_3           1.681441     3\n"
     ]
    }
   ],
   "source": [
    "class Range:\n",
    "    def __init__(self, minvalue, maxvalue, incr=1):\n",
    "        self._minvalue = minvalue\n",
    "        self._maxvalue = maxvalue\n",
    "        self._incr = incr\n",
    "    def values(self):\n",
    "        return range(self._minvalue, self._maxvalue, self._incr) \n",
    "\n",
    "class Params:\n",
    "    def __init__(self, num_clusters):\n",
    "        self._num_clusters = num_clusters\n",
    "        self._model_name = 'ch09eu.london_station_clusters_{}'.format(num_clusters)\n",
    "        self._train_query = \"\"\"\n",
    "          CREATE OR REPLACE MODEL {}\n",
    "          OPTIONS(model_type='kmeans', \n",
    "                  num_clusters={}, \n",
    "                  standardize_features = true) AS\n",
    "          SELECT * except(station_name)\n",
    "          from ch09eu.stationstats\n",
    "        \"\"\".format(self._model_name, self._num_clusters)\n",
    "        self._eval_query = \"\"\"\n",
    "          SELECT davies_bouldin_index AS error\n",
    "          FROM ML.EVALUATE(MODEL {});\n",
    "        \"\"\".format(self._model_name)\n",
    "        self._error = None\n",
    "        \n",
    "    def run(self):\n",
    "        bq = bigquery.Client(project=PROJECT)\n",
    "        job = bq.query(self._train_query, location='EU')\n",
    "        job.result() # wait for job to finish\n",
    "        evaldf = bq.query(self._eval_query, location='EU').to_dataframe()\n",
    "        self._error = evaldf['error'][0]\n",
    "        return self\n",
    "    \n",
    "    def __str__(self):\n",
    "        fmt = '{!s:<40} {:>10f} {:>5d}'\n",
    "        return fmt.format(self._model_name, self._error, self._num_clusters)\n",
    "    \n",
    "def train_and_evaluate(num_clusters: Range, max_concurrent=3):\n",
    "    # grid search means to try all possible values in range\n",
    "    params = []\n",
    "    for k in num_clusters.values():\n",
    "        params.append(Params(k))\n",
    "    \n",
    "    # run all the jobs\n",
    "    print('Grid search of {} possible parameters'.format(len(params)))\n",
    "    pool = ThreadPool(max_concurrent)\n",
    "    results = pool.map(lambda p: p.run(), params)\n",
    "    \n",
    "    # sort in ascending order\n",
    "    return sorted(results, key=lambda p: p._error)\n",
    "    \n",
    "params = train_and_evaluate(Range(3, 20))\n",
    "print(*params, sep='\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the error has kept decreasing, it appears that we need to experiment with even more clusters. 19 may itself be too few ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1b. Grid Search through Scripting and dynamic SQL\n",
    "\n",
    "Scripting can simplify the above code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bigquery\n",
    "DECLARE NUM_CLUSTERS INT64 DEFAULT 3;\n",
    "DECLARE MIN_ERROR FLOAT64 DEFAULT 1000.0;\n",
    "DECLARE BEST_NUM_CLUSTERS INT64 DEFAULT -1;\n",
    "DECLARE MODEL_NAME STRING;\n",
    "DECLARE error FLOAT64 DEFAULT 0;\n",
    " \n",
    "WHILE NUM_CLUSTERS < 8 DO\n",
    " \n",
    "  SET MODEL_NAME = CONCAT('ch09eu.london_station_clusters_', \n",
    "                            CAST(NUM_CLUSTERS AS STRING));\n",
    " \n",
    "  EXECUTE IMMEDIATE format(\"\"\"\n",
    "  CREATE OR REPLACE MODEL %s\n",
    "    OPTIONS(model_type='kmeans', \n",
    "            num_clusters=%d, \n",
    "            standardize_features = true) AS\n",
    "    SELECT * except(station_name)\n",
    "    from ch09eu.stationstats;\n",
    "  \"\"\", MODEL_NAME, NUM_CLUSTERS);\n",
    "    \n",
    "  EXECUTE IMMEDIATE format(\"\"\"\n",
    "    SELECT davies_bouldin_index FROM ML.EVALUATE(MODEL %s);\n",
    "  \"\"\", MODEL_NAME) INTO error;\n",
    "  \n",
    "    IF error < MIN_ERROR THEN\n",
    "       SET MIN_ERROR = error;\n",
    "       SET BEST_NUM_CLUSTERS = NUM_CLUSTERS;\n",
    "    END IF;\n",
    "  SET NUM_CLUSTERS = NUM_CLUSTERS + 1;\n",
    " \n",
    "END WHILE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Bayesian optimization\n",
    "\n",
    "As the number of possible parameters grows, a grid search becomes increasingly wasteful. It is better to use a more efficient search algorithm and that's where Cloud AI Platform's hyperparameter tuning can be helpful.\n",
    "\n",
    "I'll demonstrate this on tuning the feature engineering and number of nodes of a DNN model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting hyperparam.yaml\n"
     ]
    }
   ],
   "source": [
    "%%writefile hyperparam.yaml\n",
    "trainingInput:\n",
    "  scaleTier: CUSTOM\n",
    "  masterType: standard   # See: https://cloud.google.com/ml-engine/docs/tensorflow/machine-types\n",
    "  hyperparameters:\n",
    "    goal: MINIMIZE\n",
    "    maxTrials: 10\n",
    "    maxParallelTrials: 2\n",
    "    hyperparameterMetricTag: mean_absolute_error\n",
    "    params:\n",
    "    - parameterName: afternoon_start\n",
    "      type: INTEGER\n",
    "      minValue: 9\n",
    "      maxValue: 12\n",
    "      scaleType: UNIT_LINEAR_SCALE\n",
    "    - parameterName: afternoon_end\n",
    "      type: INTEGER\n",
    "      minValue: 15\n",
    "      maxValue: 19\n",
    "      scaleType: UNIT_LINEAR_SCALE\n",
    "    - parameterName: num_nodes_0\n",
    "      type: INTEGER\n",
    "      minValue: 10\n",
    "      maxValue: 100\n",
    "      scaleType: UNIT_LOG_SCALE\n",
    "    - parameterName: num_nodes_1\n",
    "      type: INTEGER\n",
    "      minValue: 3\n",
    "      maxValue: 10\n",
    "      scaleType: UNIT_LINEAR_SCALE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting setup.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile setup.py\n",
    "from setuptools import setup\n",
    "\n",
    "setup(name='trainer',\n",
    "      version='1.0',\n",
    "      description='Tune BigQuery ML',\n",
    "      url='http://github.com/GoogleCloudPlatform/bigquery-oreilly-book',\n",
    "      author='V Lakshmanan',\n",
    "      author_email='nobody@google.com',\n",
    "      license='Apache2',\n",
    "      packages=['trainer'],\n",
    "      package_data={'': ['privatekey.json']},\n",
    "      install_requires=[\n",
    "          'google-cloud-bigquery==1.15.0',\n",
    "          'cloudml-hypertune',  # Required for hyperparameter tuning.\n",
    "      ],\n",
    "      zip_safe=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "mkdir -p trainer\n",
    "touch trainer/__init__.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "### You can get your project number from the GCP home page\n",
    "\n",
    "KEYFILE=trainer/privatekey.json\n",
    "PROJECTNUMBER=663413318684    ## CHANGE THIS\n",
    "if [ ! -f $KEYFILE ]; then\n",
    "  gcloud iam service-accounts keys create \\\n",
    "      --iam-account ${PROJECTNUMBER}-compute@developer.gserviceaccount.com \\\n",
    "      $KEYFILE\n",
    "fi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting trainer/train_and_eval.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile trainer/train_and_eval.py\n",
    "import argparse\n",
    "import hypertune\n",
    "import json\n",
    "import logging\n",
    "import pkgutil\n",
    "from google.oauth2.service_account import Credentials as sac\n",
    "\n",
    "from google.cloud import bigquery\n",
    "\n",
    "def get_credentials():\n",
    "    privatekey = pkgutil.get_data('trainer', 'privatekey.json')\n",
    "    service_account_info = json.loads(privatekey.decode('utf-8'))\n",
    "    return sac.from_service_account_info(service_account_info)\n",
    "    \n",
    "def train_and_evaluate(args):        \n",
    "    model_name = \"ch09eu.bicycle_model_dnn_{}_{}_{}_{}\".format(\n",
    "        args.afternoon_start, args.afternoon_end, args.num_nodes_0, args.num_nodes_1\n",
    "    )\n",
    "    train_query = \"\"\"\n",
    "        CREATE OR REPLACE MODEL {}\n",
    "        TRANSFORM(* EXCEPT(start_date)\n",
    "                  , IF(EXTRACT(dayofweek FROM start_date) BETWEEN 2 and 6, 'weekday', 'weekend') as dayofweek\n",
    "                  , ML.BUCKETIZE(EXTRACT(HOUR FROM start_date), [5, {}, {}]) AS hourofday\n",
    "        )\n",
    "        OPTIONS(input_label_cols=['duration'], \n",
    "                model_type='dnn_regressor',\n",
    "                hidden_units=[{}, {}])\n",
    "        AS\n",
    "\n",
    "        SELECT \n",
    "          duration\n",
    "          , start_station_name\n",
    "          , start_date\n",
    "        FROM `bigquery-public-data`.london_bicycles.cycle_hire\n",
    "    \"\"\".format(model_name, \n",
    "               args.afternoon_start, \n",
    "               args.afternoon_end,\n",
    "               args.num_nodes_0,\n",
    "               args.num_nodes_1)\n",
    "    logging.info(train_query)\n",
    "    bq = bigquery.Client(project=args.project, \n",
    "                         location=args.location, \n",
    "                         credentials=get_credentials())\n",
    "    job = bq.query(train_query)\n",
    "    job.result() # wait for job to finish\n",
    "    \n",
    "    eval_query = \"\"\"\n",
    "        SELECT mean_absolute_error \n",
    "        FROM ML.EVALUATE(MODEL {})\n",
    "    \"\"\".format(model_name)\n",
    "    logging.info(eval_info)\n",
    "    evaldf = bq.query(eval_query).to_dataframe()\n",
    "    return evaldf['mean_absolute_error'][0]    \n",
    "    \n",
    "\n",
    "if __name__ == '__main__':\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument('--afternoon_start', type=int, default=10)\n",
    "    parser.add_argument('--afternoon_end', type=int, default=17)\n",
    "    parser.add_argument('--num_nodes_0', type=int, default=10)\n",
    "    parser.add_argument('--num_nodes_1', type=int, default=5)\n",
    "    parser.add_argument('--location', type=str, default='US')\n",
    "    parser.add_argument('--project', type=str, required=True)\n",
    "    parser.add_argument('--job-dir', default='ignored') # output directory to save artifacts. we have none\n",
    "\n",
    "    # get args and invoke model\n",
    "    args = parser.parse_args()\n",
    "    error = train_and_evaluate(args)\n",
    "    logging.info('{} Resulting mean_absolute_error: {}'.format(args.__dict__, error)) \n",
    "\n",
    "    # write out the metric so that the executable can be\n",
    "    # invoked again with next set of metrics\n",
    "    hpt = hypertune.HyperTune()\n",
    "    hpt.report_hyperparameter_tuning_metric(\n",
    "       hyperparameter_metric_tag='mean_absolute_error',\n",
    "       metric_value=error,\n",
    "       global_step=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "jobId: bqml_hparam_190701_161928\n",
      "state: QUEUED\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Job [bqml_hparam_190701_161928] submitted successfully.\n",
      "Your job is still active. You may view the status of your job with the command\n",
      "\n",
      "  $ gcloud ai-platform jobs describe bqml_hparam_190701_161928\n",
      "\n",
      "or continue streaming the logs with the command\n",
      "\n",
      "  $ gcloud ai-platform jobs stream-logs bqml_hparam_190701_161928\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "PROJECT=cloud-training-demos #CHANGE THIS\n",
    "BUCKET=cloud-training-demos-ml  ## CHANGE THIS\n",
    "JOBNAME=bqml_hparam_$(date -u +%y%m%d_%H%M%S)\n",
    "REGION=europe-west1\n",
    "gcloud ai-platform jobs submit training $JOBNAME \\\n",
    "  --runtime-version=1.13 \\\n",
    "  --python-version=3.5 \\\n",
    "  --region=$REGION \\\n",
    "  --module-name=trainer.train_and_eval \\\n",
    "  --package-path=$(pwd)/trainer \\\n",
    "  --job-dir=gs://$BUCKET/hparam/ \\\n",
    "  --config=hyperparam.yaml \\\n",
    "  -- \\\n",
    "  --project=$PROJECT --location=EU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copyright 2019 Google Inc. Licensed under the Apache License, Version 2.0 (the \"License\"); you may not use this file except in compliance with the License. You may obtain a copy of the License at http://www.apache.org/licenses/LICENSE-2.0 Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License."
   ]
  }
 ],
 "metadata": {
  "environment": {
   "name": "tf2-gpu.2-1.m46",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-1:m46"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
