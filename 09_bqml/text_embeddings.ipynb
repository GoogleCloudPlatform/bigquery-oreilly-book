{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Document embeddings in BigQuery for document similarity and clustering tasks\n",
    "\n",
    "This notebook shows how to do use a pre-trained embedding as a vector representation of a natural language text column.\n",
    "Given this embedding, we can load it as a BQ-ML model and then carry out document similarity or clustering.\n",
    "\n",
    "This notebook accompanies the following Medium blog post:\n",
    "https://medium.com/@lakshmanok/how-to-do-text-similarity-search-and-document-clustering-in-bigquery-75eb8f45ab65"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embedding model for documents\n",
    "\n",
    "We're going to use a model that has been pretrained on Google News. Here's an example of how it works in Python. We will use it directly in BigQuery, however."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "keras_layer_3 (KerasLayer)   (None, 20)                400020    \n",
      "=================================================================\n",
      "Total params: 400,020\n",
      "Trainable params: 0\n",
      "Non-trainable params: 400,020\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 0.52828205, -0.814417  ,  2.7678437 , -0.70152074, -0.99541044,\n",
       "        -2.9311025 , -1.3798233 ,  0.10915907,  0.8491049 , -1.6155498 ,\n",
       "        -1.1453229 ,  1.2871503 , -1.0593784 ,  0.32060066, -3.060015  ,\n",
       "         2.4751766 ,  2.9106884 , -2.6531873 , -2.379123  , -0.58328384]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_hub as tfhub\n",
    "\n",
    "model = tf.keras.Sequential()\n",
    "model.add(tfhub.KerasLayer(\"https://tfhub.dev/google/tf2-preview/gnews-swivel-20dim/1\",\n",
    "                           output_shape=[20], input_shape=[], dtype=tf.string))\n",
    "model.summary()\n",
    "model.predict([\"\"\"\n",
    "Long years ago, we made a tryst with destiny; and now the time comes when we shall redeem our pledge, not wholly or in full measure, but very substantially. At the stroke of the midnight hour, when the world sleeps, India will awake to life and freedom.\n",
    "A moment comes, which comes but rarely in history, when we step out from the old to the new -- when an age ends, and when the soul of a nation, long suppressed, finds utterance. \n",
    "\"\"\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading model into BigQuery\n",
    "\n",
    "The Swivel model above is already available in SavedModel format. But we need it on Google Cloud Storage before we can load it into BigQuery."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "assets/\n",
      "assets/tokens.txt\n",
      "saved_model.pb\n",
      "variables/\n",
      "variables/variables.data-00000-of-00001\n",
      "variables/variables.index\n",
      "Model artifacts are now at gs://ai-analytics-solutions-kfpdemo/swivel/*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Copying file://swivel/swivel.tar.gz [Content-Type=application/x-tar]...\n",
      "Copying file://swivel/saved_model.pb [Content-Type=application/octet-stream]...\n",
      "Copying file://swivel/assets/tokens.txt [Content-Type=text/plain]...\n",
      "Copying file://swivel/variables/variables.index [Content-Type=application/octet-stream]...\n",
      "Copying file://swivel/variables/variables.data-00000-of-00001 [Content-Type=application/octet-stream]...\n",
      "/ [5/5 files][  3.2 MiB/  3.2 MiB] 100% Done                                    \n",
      "Operation completed over 5 objects/3.2 MiB.                                      \n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "BUCKET=ai-analytics-solutions-kfpdemo   # CHANGE AS NEEDED\n",
    "\n",
    "rm -rf tmp\n",
    "mkdir tmp\n",
    "FILE=swivel.tar.gz\n",
    "wget --quiet -O tmp/swivel.tar.gz  https://tfhub.dev/google/tf2-preview/gnews-swivel-20dim/1?tf-hub-format=compressed\n",
    "cd tmp\n",
    "tar xvfz swivel.tar.gz\n",
    "cd ..\n",
    "mv tmp swivel\n",
    "gsutil -m cp -R swivel gs://${BUCKET}/swivel\n",
    "rm -rf swivel\n",
    "\n",
    "echo \"Model artifacts are now at gs://${BUCKET}/swivel/*\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's load the model into a BigQuery dataset named advdata (create it if necessary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%bigquery\n",
    "CREATE OR REPLACE MODEL advdata.swivel_text_embed\n",
    "OPTIONS(model_type='tensorflow', model_path='gs://ai-analytics-solutions-kfpdemo/swivel/*')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the BigQuery web console, click on \"schema\" tab for the newly loaded model. We see that the input is called sentences and the output is called output_0:\n",
    "<img src=\"swivel_schema.png\" />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>output_0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[-0.09961678087711334, -1.1282159090042114, 2....</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            output_0\n",
       "0  [-0.09961678087711334, -1.1282159090042114, 2...."
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%bigquery\n",
    "SELECT output_0 FROM\n",
    "ML.PREDICT(MODEL advdata.swivel_text_embed,(\n",
    "SELECT \"Long years ago, we made a tryst with destiny; and now the time comes when we shall redeem our pledge, not wholly or in full measure, but very substantially.\" AS sentences))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Document search\n",
    "\n",
    "Let's use the embeddings to return similar strings. We'll use the comments field of a storm reports table from NOAA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>julian_day</th>\n",
       "      <th>location</th>\n",
       "      <th>comments</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>19</td>\n",
       "      <td>POINT(-85.18 32.49)</td>\n",
       "      <td>TREES DOWN NEAR THE INTERSECTION OF LEE RD 440...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>43</td>\n",
       "      <td>POINT(-85.13 32.49)</td>\n",
       "      <td>REPORTS OF TREES DOWN IN VARIOUS LOCATIONS IN ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>62</td>\n",
       "      <td>POINT(-85.24 32.6)</td>\n",
       "      <td>CORRECTS PREVIOUS TORNADO REPORT FROM SALEM. U...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>85</td>\n",
       "      <td>POINT(-85.1 32.55)</td>\n",
       "      <td>A TREE WAS DOWNED ONTO A HOME. (BMX)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>158</td>\n",
       "      <td>POINT(-85.42 32.6)</td>\n",
       "      <td>TREE DOWN ON A HOME. TIME ESTIMATED FROM RADAR...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>158</td>\n",
       "      <td>POINT(-85.42 32.51)</td>\n",
       "      <td>MULTIPLE TREES DOWN ON LEE ROAD 29. TIME ESTIM...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>158</td>\n",
       "      <td>POINT(-85.18 32.71)</td>\n",
       "      <td>TREES DOWN IN BEULAH. TIME ESTIMATED FROM RADA...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>158</td>\n",
       "      <td>POINT(-85.09 32.54)</td>\n",
       "      <td>MULTIPLE TREES DOWN IN SMITHS STATION. TIME ES...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>190</td>\n",
       "      <td>POINT(-85.49 32.67)</td>\n",
       "      <td>TREES DOWN NEAR THE INTERSECTION OF LEE RD 147...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>217</td>\n",
       "      <td>POINT(-85.07 32.52)</td>\n",
       "      <td>CORRECTS PREVIOUS TSTM WND DMG REPORT FROM 1 E...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   julian_day             location  \\\n",
       "0          19  POINT(-85.18 32.49)   \n",
       "1          43  POINT(-85.13 32.49)   \n",
       "2          62   POINT(-85.24 32.6)   \n",
       "3          85   POINT(-85.1 32.55)   \n",
       "4         158   POINT(-85.42 32.6)   \n",
       "5         158  POINT(-85.42 32.51)   \n",
       "6         158  POINT(-85.18 32.71)   \n",
       "7         158  POINT(-85.09 32.54)   \n",
       "8         190  POINT(-85.49 32.67)   \n",
       "9         217  POINT(-85.07 32.52)   \n",
       "\n",
       "                                            comments  \n",
       "0  TREES DOWN NEAR THE INTERSECTION OF LEE RD 440...  \n",
       "1  REPORTS OF TREES DOWN IN VARIOUS LOCATIONS IN ...  \n",
       "2  CORRECTS PREVIOUS TORNADO REPORT FROM SALEM. U...  \n",
       "3               A TREE WAS DOWNED ONTO A HOME. (BMX)  \n",
       "4  TREE DOWN ON A HOME. TIME ESTIMATED FROM RADAR...  \n",
       "5  MULTIPLE TREES DOWN ON LEE ROAD 29. TIME ESTIM...  \n",
       "6  TREES DOWN IN BEULAH. TIME ESTIMATED FROM RADA...  \n",
       "7  MULTIPLE TREES DOWN IN SMITHS STATION. TIME ES...  \n",
       "8  TREES DOWN NEAR THE INTERSECTION OF LEE RD 147...  \n",
       "9  CORRECTS PREVIOUS TSTM WND DMG REPORT FROM 1 E...  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%bigquery\n",
    "SELECT \n",
    "  EXTRACT(DAYOFYEAR from timestamp) AS julian_day,\n",
    "  ST_GeogPoint(longitude, latitude) AS location,\n",
    "  comments\n",
    "FROM `bigquery-public-data.noaa_preliminary_severe_storms.wind_reports`\n",
    "WHERE EXTRACT(YEAR from timestamp) = 2019\n",
    "LIMIT 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's define a distance function and then do a search for matching documents to the search string \"power line down on a home\". Note that the matches include \"house\" as a synonym for home. And not as good, but close matches all include \"power line\" as the more distinctive term."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>termdist</th>\n",
       "      <th>comments</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.959289</td>\n",
       "      <td>POWER LINE DOWN ON HOUSE (ILX)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.959289</td>\n",
       "      <td>POWER LINE DOWN ON HOUSE. (BGM)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.218646</td>\n",
       "      <td>TREE DOWN ON A POWER LINE ON TATE RD. (RNK)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.277504</td>\n",
       "      <td>TREE DOWN ON A POWER LINE. (TAE)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.277504</td>\n",
       "      <td>TREE DOWN ON A POWER LINE. (DVN)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.332273</td>\n",
       "      <td>TREE DOWN ON CR450 AND POWER LINE DOWN ON CR 4...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.370752</td>\n",
       "      <td>POWER LINE DOWN ON BOWEN ROAD IN KING. (RNK)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1.370996</td>\n",
       "      <td>TREE DOWN... TAKING DOWN A POWER LINE... AT IN...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1.412945</td>\n",
       "      <td>POWER LINES KNOCKED DOWN ON SIERRA VISTA DR NE...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1.415289</td>\n",
       "      <td>TREE DOWN ON POWER LINE. (RAH)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   termdist                                           comments\n",
       "0  0.959289                     POWER LINE DOWN ON HOUSE (ILX)\n",
       "1  0.959289                    POWER LINE DOWN ON HOUSE. (BGM)\n",
       "2  1.218646        TREE DOWN ON A POWER LINE ON TATE RD. (RNK)\n",
       "3  1.277504                   TREE DOWN ON A POWER LINE. (TAE)\n",
       "4  1.277504                   TREE DOWN ON A POWER LINE. (DVN)\n",
       "5  1.332273  TREE DOWN ON CR450 AND POWER LINE DOWN ON CR 4...\n",
       "6  1.370752       POWER LINE DOWN ON BOWEN ROAD IN KING. (RNK)\n",
       "7  1.370996  TREE DOWN... TAKING DOWN A POWER LINE... AT IN...\n",
       "8  1.412945  POWER LINES KNOCKED DOWN ON SIERRA VISTA DR NE...\n",
       "9  1.415289                     TREE DOWN ON POWER LINE. (RAH)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%bigquery\n",
    "CREATE TEMPORARY FUNCTION td(a ARRAY<FLOAT64>, b ARRAY<FLOAT64>, idx INT64) AS (\n",
    "   (a[OFFSET(idx)] - b[OFFSET(idx)]) * (a[OFFSET(idx)] - b[OFFSET(idx)])\n",
    ");\n",
    "\n",
    "CREATE TEMPORARY FUNCTION term_distance(a ARRAY<FLOAT64>, b ARRAY<FLOAT64>) AS ((\n",
    "   SELECT SQRT(SUM( td(a, b, idx))) FROM UNNEST(GENERATE_ARRAY(0, 19)) idx\n",
    "));\n",
    "\n",
    "WITH search_term AS (\n",
    "  SELECT output_0 AS term_embedding FROM ML.PREDICT(MODEL advdata.swivel_text_embed,(SELECT \"power line down on a home\" AS sentences))\n",
    ")\n",
    "\n",
    "SELECT\n",
    "  term_distance(term_embedding, output_0) AS termdist,\n",
    "  comments\n",
    "FROM ML.PREDICT(MODEL advdata.swivel_text_embed,(\n",
    "  SELECT comments, LOWER(comments) AS sentences\n",
    "  FROM `bigquery-public-data.noaa_preliminary_severe_storms.wind_reports`\n",
    "  WHERE EXTRACT(YEAR from timestamp) = 2019\n",
    ")), search_term\n",
    "ORDER By termdist ASC\n",
    "LIMIT 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Document clustering\n",
    "\n",
    "We can use the embeddings as input to a K-Means clustering model. To make things interesting, let's also include the day and location.\n",
    "K-Means at present doesn't accept arrays as input, so I'm defining a function to make it a struct with named parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bigquery\n",
    "CREATE TEMPORARY FUNCTION arr_to_input_20(arr ARRAY<FLOAT64>)\n",
    "RETURNS \n",
    "STRUCT<p1 FLOAT64, p2 FLOAT64, p3 FLOAT64, p4 FLOAT64,\n",
    "       p5 FLOAT64, p6 FLOAT64, p7 FLOAT64, p8 FLOAT64, \n",
    "       p9 FLOAT64, p10 FLOAT64, p11 FLOAT64, p12 FLOAT64, \n",
    "       p13 FLOAT64, p14 FLOAT64, p15 FLOAT64, p16 FLOAT64,\n",
    "       p17 FLOAT64, p18 FLOAT64, p19 FLOAT64, p20 FLOAT64>\n",
    "\n",
    "AS (\n",
    "STRUCT(\n",
    "    arr[OFFSET(0)]\n",
    "    , arr[OFFSET(1)]\n",
    "    , arr[OFFSET(2)]\n",
    "    , arr[OFFSET(3)]\n",
    "    , arr[OFFSET(4)]\n",
    "    , arr[OFFSET(5)]\n",
    "    , arr[OFFSET(6)]\n",
    "    , arr[OFFSET(7)]\n",
    "    , arr[OFFSET(8)]\n",
    "    , arr[OFFSET(9)]\n",
    "    , arr[OFFSET(10)]\n",
    "    , arr[OFFSET(11)]\n",
    "    , arr[OFFSET(12)]\n",
    "    , arr[OFFSET(13)]\n",
    "    , arr[OFFSET(14)]\n",
    "    , arr[OFFSET(15)]\n",
    "    , arr[OFFSET(16)]\n",
    "    , arr[OFFSET(17)]\n",
    "    , arr[OFFSET(18)]\n",
    "    , arr[OFFSET(19)]    \n",
    "));\n",
    "\n",
    "\n",
    "CREATE OR REPLACE MODEL advdata.storm_reports_clustering\n",
    "OPTIONS(model_type='kmeans', NUM_CLUSTERS=10) AS\n",
    "\n",
    "SELECT\n",
    "  arr_to_input_20(output_0) AS comments_embed,\n",
    "  EXTRACT(DAYOFYEAR from timestamp) AS julian_day,\n",
    "  longitude, latitude\n",
    "FROM ML.PREDICT(MODEL advdata.swivel_text_embed,(\n",
    "  SELECT timestamp, longitude, latitude, LOWER(comments) AS sentences\n",
    "  FROM `bigquery-public-data.noaa_preliminary_severe_storms.wind_reports`\n",
    "  WHERE EXTRACT(YEAR from timestamp) = 2019\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The resulting clusters look like this\n",
    "<img src=\"storm_reports_clusters.png\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Show a few of the comments from cluster #1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentences</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(iln)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(iln)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(cle)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(iln)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>asos station ktol toledo. (cle)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>(cle)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>pea size hail also reported. (cle)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>(pub)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>corrects previous tstm wnd gst report from 9 s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>(rlx)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           sentences\n",
       "0                                              (iln)\n",
       "1                                              (iln)\n",
       "2                                              (cle)\n",
       "3                                              (iln)\n",
       "4                    asos station ktol toledo. (cle)\n",
       "5                                              (cle)\n",
       "6                 pea size hail also reported. (cle)\n",
       "7                                              (pub)\n",
       "8  corrects previous tstm wnd gst report from 9 s...\n",
       "9                                              (rlx)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%bigquery\n",
    "CREATE TEMPORARY FUNCTION arr_to_input_20(arr ARRAY<FLOAT64>)\n",
    "RETURNS \n",
    "STRUCT<p1 FLOAT64, p2 FLOAT64, p3 FLOAT64, p4 FLOAT64,\n",
    "       p5 FLOAT64, p6 FLOAT64, p7 FLOAT64, p8 FLOAT64, \n",
    "       p9 FLOAT64, p10 FLOAT64, p11 FLOAT64, p12 FLOAT64, \n",
    "       p13 FLOAT64, p14 FLOAT64, p15 FLOAT64, p16 FLOAT64,\n",
    "       p17 FLOAT64, p18 FLOAT64, p19 FLOAT64, p20 FLOAT64>\n",
    "\n",
    "AS (\n",
    "STRUCT(\n",
    "    arr[OFFSET(0)]\n",
    "    , arr[OFFSET(1)]\n",
    "    , arr[OFFSET(2)]\n",
    "    , arr[OFFSET(3)]\n",
    "    , arr[OFFSET(4)]\n",
    "    , arr[OFFSET(5)]\n",
    "    , arr[OFFSET(6)]\n",
    "    , arr[OFFSET(7)]\n",
    "    , arr[OFFSET(8)]\n",
    "    , arr[OFFSET(9)]\n",
    "    , arr[OFFSET(10)]\n",
    "    , arr[OFFSET(11)]\n",
    "    , arr[OFFSET(12)]\n",
    "    , arr[OFFSET(13)]\n",
    "    , arr[OFFSET(14)]\n",
    "    , arr[OFFSET(15)]\n",
    "    , arr[OFFSET(16)]\n",
    "    , arr[OFFSET(17)]\n",
    "    , arr[OFFSET(18)]\n",
    "    , arr[OFFSET(19)]    \n",
    "));\n",
    "\n",
    "SELECT sentences \n",
    "FROM ML.PREDICT(MODEL `ai-analytics-solutions.advdata.storm_reports_clustering`, \n",
    "(\n",
    "SELECT\n",
    "  sentences,\n",
    "  arr_to_input_20(output_0) AS comments_embed,\n",
    "  EXTRACT(DAYOFYEAR from timestamp) AS julian_day,\n",
    "  longitude, latitude\n",
    "FROM ML.PREDICT(MODEL advdata.swivel_text_embed,(\n",
    "  SELECT timestamp, longitude, latitude, LOWER(comments) AS sentences\n",
    "  FROM `bigquery-public-data.noaa_preliminary_severe_storms.wind_reports`\n",
    "  WHERE EXTRACT(YEAR from timestamp) = 2019\n",
    "))))\n",
    "WHERE centroid_id = 1\n",
    "LIMIT 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, these are basically uninformative comments.  How about centroid #3?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentences</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tree downed along brier ridge road. time estim...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>barn and wires down near us 62. time estimated...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>tree downed along yockey road. time estimated ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>multiple power poles down across road. time es...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>mobile home and outbuilding destroyed. signifi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1634</th>\n",
       "      <td>three trees were knocked down outside of waver...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1635</th>\n",
       "      <td>tree down across vigo road. time estimated. (iln)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1636</th>\n",
       "      <td>trees down on bluelick road. time estimated fr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1637</th>\n",
       "      <td>numerous trees reported down in huntington tow...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1638</th>\n",
       "      <td>trees down. time estimated from radar. (cle)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1639 rows Ã— 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              sentences\n",
       "0     tree downed along brier ridge road. time estim...\n",
       "1     barn and wires down near us 62. time estimated...\n",
       "2     tree downed along yockey road. time estimated ...\n",
       "3     multiple power poles down across road. time es...\n",
       "4     mobile home and outbuilding destroyed. signifi...\n",
       "...                                                 ...\n",
       "1634  three trees were knocked down outside of waver...\n",
       "1635  tree down across vigo road. time estimated. (iln)\n",
       "1636  trees down on bluelick road. time estimated fr...\n",
       "1637  numerous trees reported down in huntington tow...\n",
       "1638       trees down. time estimated from radar. (cle)\n",
       "\n",
       "[1639 rows x 1 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%bigquery\n",
    "CREATE TEMPORARY FUNCTION arr_to_input_20(arr ARRAY<FLOAT64>)\n",
    "RETURNS \n",
    "STRUCT<p1 FLOAT64, p2 FLOAT64, p3 FLOAT64, p4 FLOAT64,\n",
    "       p5 FLOAT64, p6 FLOAT64, p7 FLOAT64, p8 FLOAT64, \n",
    "       p9 FLOAT64, p10 FLOAT64, p11 FLOAT64, p12 FLOAT64, \n",
    "       p13 FLOAT64, p14 FLOAT64, p15 FLOAT64, p16 FLOAT64,\n",
    "       p17 FLOAT64, p18 FLOAT64, p19 FLOAT64, p20 FLOAT64>\n",
    "\n",
    "AS (\n",
    "STRUCT(\n",
    "    arr[OFFSET(0)]\n",
    "    , arr[OFFSET(1)]\n",
    "    , arr[OFFSET(2)]\n",
    "    , arr[OFFSET(3)]\n",
    "    , arr[OFFSET(4)]\n",
    "    , arr[OFFSET(5)]\n",
    "    , arr[OFFSET(6)]\n",
    "    , arr[OFFSET(7)]\n",
    "    , arr[OFFSET(8)]\n",
    "    , arr[OFFSET(9)]\n",
    "    , arr[OFFSET(10)]\n",
    "    , arr[OFFSET(11)]\n",
    "    , arr[OFFSET(12)]\n",
    "    , arr[OFFSET(13)]\n",
    "    , arr[OFFSET(14)]\n",
    "    , arr[OFFSET(15)]\n",
    "    , arr[OFFSET(16)]\n",
    "    , arr[OFFSET(17)]\n",
    "    , arr[OFFSET(18)]\n",
    "    , arr[OFFSET(19)]    \n",
    "));\n",
    "\n",
    "SELECT sentences \n",
    "FROM ML.PREDICT(MODEL `ai-analytics-solutions.advdata.storm_reports_clustering`, \n",
    "(\n",
    "SELECT\n",
    "  sentences,\n",
    "  arr_to_input_20(output_0) AS comments_embed,\n",
    "  EXTRACT(DAYOFYEAR from timestamp) AS julian_day,\n",
    "  longitude, latitude\n",
    "FROM ML.PREDICT(MODEL advdata.swivel_text_embed,(\n",
    "  SELECT timestamp, longitude, latitude, LOWER(comments) AS sentences\n",
    "  FROM `bigquery-public-data.noaa_preliminary_severe_storms.wind_reports`\n",
    "  WHERE EXTRACT(YEAR from timestamp) = 2019\n",
    "))))\n",
    "WHERE centroid_id = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These are all reports that were validated in some way by radar!!!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copyright 2020 Google Inc. Licensed under the Apache License, Version 2.0 (the \"License\"); you may not use this file except in compliance with the License. You may obtain a copy of the License at http://www.apache.org/licenses/LICENSE-2.0 Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "name": "tf2-gpu.2-1.m54",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-1:m54"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
